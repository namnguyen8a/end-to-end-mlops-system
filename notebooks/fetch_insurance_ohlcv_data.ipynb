{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fetch 10 Years OHLCV Data for Insurance HOSE Stocks\n",
        "\n",
        "This notebook fetches 10 years of historical OHLCV (Open, High, Low, Close, Volume) data for all insurance stocks listed on HOSE and saves it to a CSV file for model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n",
            "Data will be saved to: ../data/processed\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from vnstock import Vnstock\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Set up paths\n",
        "DATA_RAW_PATH = '../data/raw'\n",
        "DATA_PROCESSED_PATH = '../data/processed'\n",
        "\n",
        "# Create processed directory if it doesn't exist\n",
        "os.makedirs(DATA_PROCESSED_PATH, exist_ok=True)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"Data will be saved to: {DATA_PROCESSED_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5 insurance stocks:\n",
            "['BIC', 'BMI', 'BVH', 'MIG', 'PGI']\n",
            "\n",
            "Stock details:\n",
            "    Sàn           Ngành Mã CK  \\\n",
            "0  HOSE  Ngành Bảo hiểm   BIC   \n",
            "1  HOSE  Ngành Bảo hiểm   BMI   \n",
            "2  HOSE  Ngành Bảo hiểm   BVH   \n",
            "3  HOSE  Ngành Bảo hiểm   MIG   \n",
            "4  HOSE  Ngành Bảo hiểm   PGI   \n",
            "\n",
            "                                         Tên công ty  \n",
            "0  Tổng CTCP Bảo hiểm Ngân hàng Đầu tư và Phát tr...  \n",
            "1                                 Tổng CTCP Bảo Minh  \n",
            "2                                  Tập đoàn Bảo Việt  \n",
            "3                        Tổng CTCP Bảo hiểm Quân Đội  \n",
            "4                      Tổng CTCP Bảo hiểm Petrolimex  \n"
          ]
        }
      ],
      "source": [
        "# Load insurance HOSE stock list\n",
        "insurance_stocks_df = pd.read_csv(f'{DATA_RAW_PATH}/insurance_hose_ticket_name.csv')\n",
        "insurance_stocks_list = insurance_stocks_df['Mã CK'].tolist()\n",
        "\n",
        "print(f\"Found {len(insurance_stocks_list)} insurance stocks:\")\n",
        "print(insurance_stocks_list)\n",
        "print(\"\\nStock details:\")\n",
        "print(insurance_stocks_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Date range: 2014-01-01 to 2024-12-31\n",
            "Interval: 1D\n"
          ]
        }
      ],
      "source": [
        "# Configure date range for 10 years of data\n",
        "# Fetch data from 2014-01-01 to 2024-12-31 (10 years)\n",
        "START_DATE = '2014-01-01'\n",
        "END_DATE = '2024-12-31'\n",
        "INTERVAL = '1D'  # Daily data\n",
        "\n",
        "print(f\"Date range: {START_DATE} to {END_DATE}\")\n",
        "print(f\"Interval: {INTERVAL}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing with stock: BIC\n",
            "\n",
            "Successfully fetched data for BIC\n",
            "Shape: (2872, 6)\n",
            "\n",
            "Columns: ['time', 'open', 'high', 'low', 'close', 'volume']\n",
            "\n",
            "First few rows:\n",
            "        time  open  high   low  close  volume\n",
            "0 2013-07-08  3.30  3.41  3.30   3.37    4960\n",
            "1 2013-07-09  3.30  3.34  3.27   3.34    6400\n",
            "2 2013-07-10  3.34  3.34  3.24   3.34    5580\n",
            "3 2013-07-11  3.34  3.34  3.34   3.34     110\n",
            "4 2013-07-12  3.41  3.41  3.27   3.37   21170\n",
            "\n",
            "Data types:\n",
            "time      datetime64[ns]\n",
            "open             float64\n",
            "high             float64\n",
            "low              float64\n",
            "close            float64\n",
            "volume             int64\n",
            "dtype: object\n",
            "\n",
            "Date range in data: 0 to 2871\n"
          ]
        }
      ],
      "source": [
        "# Initialize Vnstock client\n",
        "vnstock_client = Vnstock()\n",
        "\n",
        "# Test with one stock first to understand data structure\n",
        "test_symbol = insurance_stocks_list[0]\n",
        "print(f\"Testing with stock: {test_symbol}\")\n",
        "\n",
        "try:\n",
        "    stock = vnstock_client.stock(symbol=test_symbol, source='VCI')\n",
        "    test_df = stock.quote.history(start=START_DATE, end=END_DATE, interval=INTERVAL)\n",
        "    \n",
        "    print(f\"\\nSuccessfully fetched data for {test_symbol}\")\n",
        "    print(f\"Shape: {test_df.shape}\")\n",
        "    print(f\"\\nColumns: {test_df.columns.tolist()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(test_df.head())\n",
        "    print(f\"\\nData types:\")\n",
        "    print(test_df.dtypes)\n",
        "    print(f\"\\nDate range in data: {test_df.index.min()} to {test_df.index.max()}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error fetching test data: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function defined successfully!\n"
          ]
        }
      ],
      "source": [
        "# Function to fetch OHLCV data for a single stock\n",
        "def fetch_stock_data(symbol, start_date, end_date, interval='1D', source='VCI', retry_count=3):\n",
        "    \"\"\"\n",
        "    Fetch historical OHLCV data for a single stock.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    symbol : str\n",
        "        Stock symbol (e.g., 'BIC', 'BMI')\n",
        "    start_date : str\n",
        "        Start date in 'YYYY-MM-DD' format\n",
        "    end_date : str\n",
        "        End date in 'YYYY-MM-DD' format\n",
        "    interval : str\n",
        "        Data interval (default: '1D' for daily)\n",
        "    source : str\n",
        "        Data source (default: 'VCI')\n",
        "    retry_count : int\n",
        "        Number of retry attempts if request fails\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    pd.DataFrame or None\n",
        "        DataFrame with OHLCV data, or None if failed\n",
        "    \"\"\"\n",
        "    for attempt in range(retry_count):\n",
        "        try:\n",
        "            stock = vnstock_client.stock(symbol=symbol, source=source)\n",
        "            df = stock.quote.history(start=start_date, end=end_date, interval=interval)\n",
        "            \n",
        "            if df is not None and not df.empty:\n",
        "                # Add symbol column to identify the stock\n",
        "                df['symbol'] = symbol\n",
        "                # Rename 'time' column to 'date' if it exists\n",
        "                if 'time' in df.columns:\n",
        "                    df = df.rename(columns={'time': 'date'})\n",
        "                return df\n",
        "            else:\n",
        "                print(f\"  Warning: Empty data returned for {symbol}\")\n",
        "                return None\n",
        "                \n",
        "        except Exception as e:\n",
        "            if attempt < retry_count - 1:\n",
        "                print(f\"  Attempt {attempt + 1} failed for {symbol}: {e}. Retrying...\")\n",
        "                time.sleep(2)  # Wait 2 seconds before retry\n",
        "            else:\n",
        "                print(f\"  Error fetching {symbol} after {retry_count} attempts: {e}\")\n",
        "                return None\n",
        "    \n",
        "    return None\n",
        "\n",
        "print(\"Function defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting to fetch data for 5 stocks...\n",
            "============================================================\n",
            "[1/5] Fetching data for BIC... ✓ Success (2872 rows)\n",
            "[2/5] Fetching data for BMI... ✓ Success (2872 rows)\n",
            "[3/5] Fetching data for BVH... ✓ Success (2872 rows)\n",
            "[4/5] Fetching data for MIG... ✓ Success (1914 rows)\n",
            "[5/5] Fetching data for PGI... ✓ Success (2872 rows)\n",
            "============================================================\n",
            "\n",
            "Summary:\n",
            "  Successfully fetched: 5 stocks\n",
            "  Failed: 0 stocks\n"
          ]
        }
      ],
      "source": [
        "# Fetch data for all insurance stocks\n",
        "all_data_frames = []\n",
        "failed_stocks = []\n",
        "\n",
        "print(f\"Starting to fetch data for {len(insurance_stocks_list)} stocks...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for idx, symbol in enumerate(insurance_stocks_list, 1):\n",
        "    print(f\"[{idx}/{len(insurance_stocks_list)}] Fetching data for {symbol}...\", end=' ')\n",
        "    \n",
        "    df = fetch_stock_data(symbol, START_DATE, END_DATE, INTERVAL)\n",
        "    \n",
        "    if df is not None and not df.empty:\n",
        "        all_data_frames.append(df)\n",
        "        print(f\"✓ Success ({len(df)} rows)\")\n",
        "    else:\n",
        "        failed_stocks.append(symbol)\n",
        "        print(f\"✗ Failed\")\n",
        "    \n",
        "    # Add a small delay to avoid rate limiting\n",
        "    time.sleep(1)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"  Successfully fetched: {len(all_data_frames)} stocks\")\n",
        "print(f\"  Failed: {len(failed_stocks)} stocks\")\n",
        "if failed_stocks:\n",
        "    print(f\"  Failed stocks: {failed_stocks}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined dataset shape: (13402, 7)\n",
            "\n",
            "Columns: ['date', 'open', 'high', 'low', 'close', 'volume', 'symbol']\n",
            "\n",
            "First few rows:\n",
            "        date  open  high   low  close  volume symbol\n",
            "0 2013-07-08  3.30  3.41  3.30   3.37    4960    BIC\n",
            "1 2013-07-09  3.30  3.34  3.27   3.34    6400    BIC\n",
            "2 2013-07-10  3.34  3.34  3.24   3.34    5580    BIC\n",
            "3 2013-07-11  3.34  3.34  3.34   3.34     110    BIC\n",
            "4 2013-07-12  3.41  3.41  3.27   3.37   21170    BIC\n",
            "5 2013-07-15  3.41  3.41  3.37   3.41    6510    BIC\n",
            "6 2013-07-16  3.41  3.44  3.41   3.44    6000    BIC\n",
            "7 2013-07-17  3.44  3.44  3.20   3.37   10280    BIC\n",
            "8 2013-07-18  3.34  3.37  3.27   3.34    2920    BIC\n",
            "9 2013-07-19  3.41  3.41  3.30   3.34    4740    BIC\n",
            "\n",
            "Last few rows:\n",
            "            date   open   high    low  close  volume symbol\n",
            "13392 2024-12-18  21.71  21.71  21.71  21.71    3953    PGI\n",
            "13393 2024-12-19  21.71  21.71  21.71  21.71       0    PGI\n",
            "13394 2024-12-20  21.71  21.71  21.71  21.71       0    PGI\n",
            "13395 2024-12-23  21.71  21.71  21.71  21.71       0    PGI\n",
            "13396 2024-12-24  21.71  21.71  21.71  21.71     500    PGI\n",
            "13397 2024-12-25  21.71  21.71  21.71  21.71     100    PGI\n",
            "13398 2024-12-26  21.71  21.71  21.71  21.71       0    PGI\n",
            "13399 2024-12-27  21.71  21.71  21.71  21.71       1    PGI\n",
            "13400 2024-12-30  21.71  21.71  21.71  21.71       0    PGI\n",
            "13401 2024-12-31  21.71  21.71  21.71  21.71       0    PGI\n",
            "\n",
            "Unique stocks: ['BIC' 'BMI' 'BVH' 'MIG' 'PGI']\n",
            "\n",
            "Date range: 2013-07-08 00:00:00 to 2024-12-31 00:00:00\n",
            "\n",
            "Data info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13402 entries, 0 to 13401\n",
            "Data columns (total 7 columns):\n",
            " #   Column  Non-Null Count  Dtype         \n",
            "---  ------  --------------  -----         \n",
            " 0   date    13402 non-null  datetime64[ns]\n",
            " 1   open    13402 non-null  float64       \n",
            " 2   high    13402 non-null  float64       \n",
            " 3   low     13402 non-null  float64       \n",
            " 4   close   13402 non-null  float64       \n",
            " 5   volume  13402 non-null  int64         \n",
            " 6   symbol  13402 non-null  object        \n",
            "dtypes: datetime64[ns](1), float64(4), int64(1), object(1)\n",
            "memory usage: 733.0+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Combine all dataframes into one\n",
        "if all_data_frames:\n",
        "    combined_df = pd.concat(all_data_frames, ignore_index=True)\n",
        "    \n",
        "    # Rename 'time' to 'date' if it exists (for consistency)\n",
        "    if 'time' in combined_df.columns and 'date' not in combined_df.columns:\n",
        "        combined_df = combined_df.rename(columns={'time': 'date'})\n",
        "    \n",
        "    print(f\"Combined dataset shape: {combined_df.shape}\")\n",
        "    print(f\"\\nColumns: {combined_df.columns.tolist()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(combined_df.head(10))\n",
        "    print(f\"\\nLast few rows:\")\n",
        "    print(combined_df.tail(10))\n",
        "    print(f\"\\nUnique stocks: {combined_df['symbol'].unique()}\")\n",
        "    print(f\"\\nDate range: {combined_df['date'].min()} to {combined_df['date'].max()}\")\n",
        "    print(f\"\\nData info:\")\n",
        "    print(combined_df.info())\n",
        "else:\n",
        "    print(\"No data to combine!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Quality Check:\n",
            "============================================================\n",
            "\n",
            "Missing values per column:\n",
            "date      0\n",
            "open      0\n",
            "high      0\n",
            "low       0\n",
            "close     0\n",
            "volume    0\n",
            "symbol    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values percentage:\n",
            "date      0.0\n",
            "open      0.0\n",
            "high      0.0\n",
            "low       0.0\n",
            "close     0.0\n",
            "volume    0.0\n",
            "symbol    0.0\n",
            "dtype: float64\n",
            "\n",
            "Basic statistics:\n",
            "                                date          open          high  \\\n",
            "count                          13402  13402.000000  13402.000000   \n",
            "mean   2019-07-15 12:32:39.826891520     19.686685     19.976933   \n",
            "min              2013-07-08 00:00:00      2.890000      2.990000   \n",
            "25%              2016-11-14 00:00:00      9.390000      9.530000   \n",
            "50%              2019-08-23 00:00:00     13.500000     13.710000   \n",
            "75%              2022-04-29 00:00:00     23.430000     23.610000   \n",
            "max              2024-12-31 00:00:00     90.880000     92.210000   \n",
            "std                              NaN     16.589533     16.835326   \n",
            "\n",
            "                low         close        volume  \n",
            "count  13402.000000  13402.000000  1.340200e+04  \n",
            "mean      19.413414     19.708529  2.422515e+05  \n",
            "min        2.890000      2.960000  0.000000e+00  \n",
            "25%        9.250000      9.440000  1.162900e+04  \n",
            "50%       13.310000     13.570000  7.576500e+04  \n",
            "75%       23.290000     23.460000  2.750800e+05  \n",
            "max       88.890000     89.640000  5.086200e+06  \n",
            "std       16.367878     16.581595  4.223224e+05  \n",
            "\n",
            "Rows per stock:\n",
            "symbol\n",
            "BIC    2872\n",
            "BMI    2872\n",
            "BVH    2872\n",
            "MIG    1914\n",
            "PGI    2872\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values and data quality\n",
        "if all_data_frames:\n",
        "    print(\"Data Quality Check:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\\nMissing values per column:\")\n",
        "    print(combined_df.isnull().sum())\n",
        "    print(\"\\nMissing values percentage:\")\n",
        "    print((combined_df.isnull().sum() / len(combined_df) * 100).round(2))\n",
        "    print(\"\\nBasic statistics:\")\n",
        "    print(combined_df.describe())\n",
        "    \n",
        "    # Check rows per stock\n",
        "    print(\"\\nRows per stock:\")\n",
        "    print(combined_df['symbol'].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Data saved successfully to: ../data/processed/insurance_hose_ohlcv_10years.csv\n",
            "  Total rows: 13,402\n",
            "  Total columns: 7\n",
            "  File size: 0.56 MB\n",
            "\n",
            "Verifying saved file...\n",
            "  Verified: 13402 rows loaded from CSV\n",
            "  Columns: ['date', 'open', 'high', 'low', 'close', 'volume', 'symbol']\n"
          ]
        }
      ],
      "source": [
        "# Save combined data to CSV\n",
        "if all_data_frames:\n",
        "    output_filename = f'{DATA_PROCESSED_PATH}/insurance_hose_ohlcv_10years.csv'\n",
        "    \n",
        "    # Ensure date column is properly formatted\n",
        "    # Rename 'time' to 'date' if it still exists\n",
        "    if 'time' in combined_df.columns and 'date' not in combined_df.columns:\n",
        "        combined_df = combined_df.rename(columns={'time': 'date'})\n",
        "    \n",
        "    if 'date' in combined_df.columns:\n",
        "        combined_df['date'] = pd.to_datetime(combined_df['date'])\n",
        "        combined_df = combined_df.sort_values(['symbol', 'date'])\n",
        "    \n",
        "    # Save to CSV\n",
        "    combined_df.to_csv(output_filename, index=False)\n",
        "    \n",
        "    print(f\"✓ Data saved successfully to: {output_filename}\")\n",
        "    print(f\"  Total rows: {len(combined_df):,}\")\n",
        "    print(f\"  Total columns: {len(combined_df.columns)}\")\n",
        "    print(f\"  File size: {os.path.getsize(output_filename) / (1024*1024):.2f} MB\")\n",
        "    \n",
        "    # Verify the saved file\n",
        "    print(\"\\nVerifying saved file...\")\n",
        "    verify_df = pd.read_csv(output_filename)\n",
        "    print(f\"  Verified: {len(verify_df)} rows loaded from CSV\")\n",
        "    print(f\"  Columns: {verify_df.columns.tolist()}\")\n",
        "else:\n",
        "    print(\"No data to save!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "The OHLCV data has been successfully fetched and saved. The dataset is ready for:\n",
        "- Feature engineering (calculating technical indicators)\n",
        "- Linear regression model training\n",
        "- Time series analysis\n",
        "\n",
        "**Next steps:**\n",
        "1. Load the CSV file: `pd.read_csv('../data/processed/insurance_hose_ohlcv_10years.csv')`\n",
        "2. Perform feature engineering (calculate 20 technical indicators)\n",
        "3. Prepare data for linear regression model training\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (mlops-system)",
      "language": "python",
      "name": "mlops-system"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
